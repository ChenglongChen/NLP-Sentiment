{"nbformat_minor": 0, "cells": [{"source": "## Upload Review Data using AzureML\n\nCreate a batch file and execute:\n    \n```\ncd \"C:\\Program Files (x86)\\Microsoft SDKs\\Azure\\AzCopy\"\nAzCopy /Source:C:\\_ilia_share\\amazon_prod_reviews_clean\\raw /Dest:https://ikcentralusstore.blob.core.windows.net/amazonrev /DestKey:dLR5lH2QN/ejGmyD61nQoh7Cc2DW8jIKhR5n5uvGu8+H3Qem4J0XzWG1/7XtBxmVlWr+y/GNRlwX4Km5YU68sg== /Pattern:\"aggressive_dedup.json\"\npause\n```", "cell_type": "markdown", "metadata": {}}, {"source": "## Load Review Data (from Blob)", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "# Idea courtesy of Thomas D.\nimport time\nSTIME = { \"start\" : time.time() }\n\ndef tic():\n    STIME[\"start\"] = time.time()\n\ndef toc():\n    elapsed = time.time() - STIME[\"start\"]\n    print(\"%.2f seconds elasped\" % elapsed)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Creating SparkContext as 'sc'\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>21</td><td>application_1469092805367_0009</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-ikclus.ftd4jbtqjxzuhd0uvhsmx0be3e.gx.internal.cloudapp.net:8088/proxy/application_1469092805367_0009/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.14:30060/node/containerlogs/container_e02_1469092805367_0009_01_000001/spark\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "Creating HiveContext as 'sqlContext'\nSparkContext and HiveContext created. Executing user code ...\n"}], "metadata": {"collapsed": false}}, {"execution_count": 3, "cell_type": "code", "source": "# paths\nblob = \"wasb://amazonrev@ikcentralusstore.blob.core.windows.net\"\njson_dta = blob + \"/aggressive_dedup.json\"", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 4, "cell_type": "code", "source": "# load data\njsonFile = sqlContext.read.json(json_dta)\njsonFile.registerTempTable(\"reviews\")\n\nprint(type(jsonFile)) #  <class 'pyspark.sql.dataframe.DataFrame'>\njsonFile.show(5)\n\n# Note: also load the IMDB data at some point\n# ...", "outputs": [{"output_type": "stream", "name": "stdout", "text": "<class 'pyspark.sql.dataframe.DataFrame'>\n+----------+-------+-------+--------------------+-----------+--------------------+---------------+--------------------+--------------+\n|      asin|helpful|overall|          reviewText| reviewTime|          reviewerID|   reviewerName|             summary|unixReviewTime|\n+----------+-------+-------+--------------------+-----------+--------------------+---------------+--------------------+--------------+\n|B003UYU16G| [0, 0]|    5.0|It is and does ex...|11 21, 2012|A00000262KYZUE4J5...| Steven N Elich|Does what it's su...|    1353456000|\n|B005FYPK9C| [0, 0]|    5.0|I was sketchy at ...| 01 8, 2013|A000008615DZQRRI9...|      mj waldon|           great buy|    1357603200|\n|B000VEBG9Y| [0, 0]|    3.0|Very mobile produ...|03 24, 2014|A00000922W28P2OCH...|Gabriel Merrill|Great product but...|    1395619200|\n|B001EJMS6K| [0, 0]|    4.0|Easy to use a mob...|03 24, 2014|A00000922W28P2OCH...|Gabriel Merrill|Great inexpensive...|    1395619200|\n|B003XJCNVO| [0, 0]|    4.0|Love this feeder....|03 24, 2014|A00000922W28P2OCH...|Gabriel Merrill|Great feeder. Wou...|    1395619200|\n+----------+-------+-------+--------------------+-----------+--------------------+---------------+--------------------+--------------+\nonly showing top 5 rows"}], "metadata": {"collapsed": false}}, {"source": "## Examine some of the reviews", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 5, "cell_type": "code", "source": "%%sql \nSELECT overall, reviewText\nFROM reviews\nLIMIT 10", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 6, "cell_type": "code", "source": "%%sql \nSELECT overall, COUNT(overall) as freq\nFROM reviews\nGROUP BY overall\nORDER by -freq", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 7, "cell_type": "code", "source": "# Create a dataframe of our reviews\n# To analyse class imbalance\n\nreviews =  sqlContext.sql(\"SELECT \" + \n                          \"CASE WHEN overall < 3 THEN 'low' \" +\n                          \"WHEN overall > 3 THEN 'high' ELSE 'mid' END as label, \" + \n                          \"reviewText as sentences \" + \n                          \"FROM reviews\")\n# Tally\n#tally = reviews.groupBy(\"label\").count()\n#tally.show()\n\"\"\"\nmid| 7,039,272\nlow|10,963,811\nhigh|64,453,794\n\"\"\"", "outputs": [{"output_type": "stream", "name": "stdout", "text": "'\\nmid| 7,039,272\\nlow|10,963,811\\nhigh|64,453,794\\n'"}], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "# Let's look at some reviews to see how clean they are\n# there seems to be lots of html formatting\nfor c,r in enumerate(reviews.take(10)):\n    print(\"%d. %s\" % (c+1,r['sentences']))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1. It is and does exactly what the description said it would be and would do. Couldn't be happier with it.\n2. I was sketchy at first about these but once you wear them for a couple hours they break in they fit good on my board an have little wear from skating in them. They are a little heavy but won't get eaten up as bad by your grip tape like poser dc shoes.\n3. Very mobile product. Efficient. Easy to use; however product needs a varmint guard. Critters are able to gorge themselves without a guard.\n4. Easy to use a mobile. If you're taller than 4ft, be ready to tuck your legs behind you as you hang and pull.\n5. Love this feeder. Heavy duty & capacity. Best feature is the large varmint guard. Definitely use a small lock or securing device on the battery housing latch. I gave 4 stars because several bolts were missing. Check contents b4 beginning.\n6. Solid, stable mount. Holds iPhone with phone protector well. I have not however used the dash mount part of this product (only windshield).\n7. I bought this pepper because I wanted a lot of cayenne powder I mean a lot. I drink shots of this powder daily and I do like it but I'm not sure if it's just me but it does not seem to strong I sweat for a minute but I feel like it could be stronger I even touched my eyes to see if it would hurt still not feeling much pain. Im one in 7 billion so do forget my review since I'm more hardcore.\n8. Beautiful photos/film with wonderful music.  Giriodi lets you know where you are with on screen notes.  It helps to keep your heart in Colorado when you can't be there.\n9. My idea of Colorado is &#34;Mountains&#34;.  Colorado Landscapes seemed to focus on the flatlands and foothills.  It gave you no idea where you were  - it could have used a narrator or notes on-screen.\n10. No matter what we did the bills just kept jamming in the machine. The bill counts were not consistent. We returned the product because it did not work correctly."}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "# Some very basic cleaning\nfrom pyspark.sql.functions import UserDefinedFunction\nfrom pyspark.sql.types import StringType, DoubleType \nfrom bs4 import BeautifulSoup\n\ndef cleanerHTML(line):\n    # html formatting\n    html_clean = BeautifulSoup(line, \"lxml\").get_text().lower()\n    # remove any double spaces, line-breaks, etc.\n    return \" \".join(html_clean.split())\n\ndef labelForResults(s):\n    # string label to numeric\n    if s == 'low':\n        return 0.0\n    elif s == 'high':\n        return 1.0\n    else:\n        return -1.0\n        \ncleaner = UserDefinedFunction(cleanerHTML, StringType())\nlabel = UserDefinedFunction(labelForResults, DoubleType())\n\ncleanedReviews = reviews.select(reviews.label,\n                                label(reviews.label).alias('sentiment'), \n                                cleaner(reviews.sentences).alias('sentences'))", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 10, "cell_type": "code", "source": "# A bit cleaner ...\nfor c,r in enumerate(cleanedReviews.take(10)):\n    print(\"%d. %s\" % (c+1,r['sentences']))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1. it is and does exactly what the description said it would be and would do. couldn't be happier with it.\n2. i was sketchy at first about these but once you wear them for a couple hours they break in they fit good on my board an have little wear from skating in them. they are a little heavy but won't get eaten up as bad by your grip tape like poser dc shoes.\n3. very mobile product. efficient. easy to use; however product needs a varmint guard. critters are able to gorge themselves without a guard.\n4. easy to use a mobile. if you're taller than 4ft, be ready to tuck your legs behind you as you hang and pull.\n5. love this feeder. heavy duty & capacity. best feature is the large varmint guard. definitely use a small lock or securing device on the battery housing latch. i gave 4 stars because several bolts were missing. check contents b4 beginning.\n6. solid, stable mount. holds iphone with phone protector well. i have not however used the dash mount part of this product (only windshield).\n7. i bought this pepper because i wanted a lot of cayenne powder i mean a lot. i drink shots of this powder daily and i do like it but i'm not sure if it's just me but it does not seem to strong i sweat for a minute but i feel like it could be stronger i even touched my eyes to see if it would hurt still not feeling much pain. im one in 7 billion so do forget my review since i'm more hardcore.\n8. beautiful photos/film with wonderful music. giriodi lets you know where you are with on screen notes. it helps to keep your heart in colorado when you can't be there.\n9. my idea of colorado is \"mountains\". colorado landscapes seemed to focus on the flatlands and foothills. it gave you no idea where you were - it could have used a narrator or notes on-screen.\n10. no matter what we did the bills just kept jamming in the machine. the bill counts were not consistent. we returned the product because it did not work correctly."}], "metadata": {"collapsed": false}}, {"execution_count": 11, "cell_type": "code", "source": "#cleanedReviews.show()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 12, "cell_type": "code", "source": "# Equalise classes \nneg_rev = cleanedReviews.filter(\"sentiment = 0.0\")\npos_rev = cleanedReviews.filter(\"sentiment = 1.0\").limit(neg_rev.count())", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "# Save data\nallData = pos_rev.unionAll(neg_rev)\nprint(allData.count()) # 21,927,622 ( = 10,963,811 * 2)\n\nallDataLoc = blob + \"/cleaned_equal_classes.json\"\nallData.write.json(allDataLoc)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "21927622"}], "metadata": {"collapsed": false}}, {"source": "## Load Clean Data", "cell_type": "markdown", "metadata": {}}, {"execution_count": 14, "cell_type": "code", "source": "allDataLoc = blob + \"/cleaned_equal_classes.json\"\nallData = sqlContext.read.json(allDataLoc)\n\ndata_count = allData.count()\nprint(data_count)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "21927622"}], "metadata": {"collapsed": false}}, {"execution_count": 32, "cell_type": "code", "source": "# Take 1 million\nsub_sample = 1000000\nsub_sample_ratio = float(sub_sample)/float(data_count)\n\nprint(sub_sample_ratio)\n\nprint(type(allData))\nallData.take(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.0456045803781\n<class 'pyspark.sql.dataframe.DataFrame'>\n[Row(label=u'high', sentences=u\"this is one of the best albums i've listened too, incredible. it doesn't get much heavier than sic. eyeless is a classic along with wait and bleed. in wait and bleed cory shows us his singing ability other than his aggressive screaming, which is very impressive. surfacing, incredible also. spit it out, amazing. trust me, this cd is great. the only tracks to be warned about are probably...1...7...10 and the last one. but still the last one and 10 along with 7 are listenable. very good album\", sentiment=1.0), Row(label=u'high', sentences=u'wow..really..what can i say? wow. ross robinson has added another to his collection of great cd\\'s. this is my favorite machine head...for some good reasons. the singer\\'s voice (flynn) has really come far in this album. the metal riffs on the guitar are toooo catchy. :-) some stand out songs are \"the blood the sweat the tears\" \"i defy\" \"desire to fire\" well..they are all pretty good actually. this cd also doesn\\'t sound like it was recorded in some garage, so the sound quality plays a big factory. i really do enjoy this cd, and often find it spinnin\\' in my diskman. thanks for reading.', sentiment=1.0), Row(label=u'high', sentences=u\"okay first off, this album is nothing like metal. some hip hop this and that, no metal. now i'm a huge metal fan, i was wishing for something near metal, but nothing remotly close. but i did enjoy it for just laying around doing nothing. it has a nice beat to it, for a slowish cd. i like come original, that's a classic song. i like the cd, but it isn't for making you get up and jump all around, more for a mellow time. thanks for reading.\", sentiment=1.0), Row(label=u'high', sentences=u\"well, lets put it this way, it touches all music tastes. from just rock (jericho, triple h, the rocks) to slow (mark henry) to the closets to metal (stone colds) which isn't really metal but the closest it comes to it. so it's a pretty good cd all together, better than i thought it'd come out. 4 stars, thanks for reading.\", sentiment=1.0), Row(label=u'high', sentences=u'this cd by rage compares to their first one. this cd has to be one of the most thoughtout cds ever. but i\\'m still sticking with my guns, the first rage cd is the best. don\\'t get me wrong, this is one of the best cds of the year. very much worth the money, and if your too cheap to put the \"$18 on the counter\" try e-bay! lol \"happy bidding!\" trust me, worth the money, great cd.', sentiment=1.0)]"}], "metadata": {"collapsed": false}}, {"execution_count": 33, "cell_type": "code", "source": "# sub_sample -> sample(boolean withReplacement, double fraction, long seed)\nsubData = allData.sample(False, sub_sample_ratio, 12345)\n\n# split intro training and test (50%, 50%)\ntrainingData, testData = neg_rev.unionAll(pos_rev).randomSplit([0.5, 0.5])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 34, "cell_type": "code", "source": "tic()\ntrainingData.show()\ntoc()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+---------+--------------------+\n|label|sentiment|           sentences|\n+-----+---------+--------------------+\n|  low|      0.0|!!!!!!!!!!!!!!!!!...|\n|  low|      0.0|!is too big for m...|\n|  low|      0.0|\"... the conserva...|\n|  low|      0.0|\"aerobics and pus...|\n|  low|      0.0|\"attention!!the s...|\n|  low|      0.0|\"backlash\" was a ...|\n|  low|      0.0|\"beautiful ruins\"...|\n|  low|      0.0|\"boxing helena\" i...|\n|  low|      0.0|\"clad\" means that...|\n|  low|      0.0|\"classic pong\" is...|\n|  low|      0.0|\"denialism\"??? lo...|\n|  low|      0.0|\"do you want to b...|\n|  low|      0.0|\"doesn't work by ...|\n|  low|      0.0|\"duvet set\" does ...|\n|  low|      0.0|\"fallen masters\" ...|\n|  low|      0.0|\"full clip\" is es...|\n|  low|      0.0|\"gods & generals\"...|\n|  low|      0.0|\"gould and lewont...|\n|  low|      0.0|\"greenhouse\" top ...|\n|  low|      0.0|\"h-he wh-whispere...|\n+-----+---------+--------------------+\nonly showing top 20 rows\n\n1625.88 seconds elasped"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "tic()\ntestData.show()\ntoc()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+---------+--------------------+\n|label|sentiment|           sentences|\n+-----+---------+--------------------+\n|  low|      0.0|!!!!**attention!!...|\n|  low|      0.0|\"...under george ...|\n|  low|      0.0|\"40 more years\" i...|\n|  low|      0.0|\"a hundred years ...|\n|  low|      0.0|\"ain't it awful\" ...|\n|  low|      0.0|\"all size fits mo...|\n|  low|      0.0|\"an unseen enemy ...|\n|  low|      0.0|\"as bradley put i...|\n|  low|      0.0|\"austenland\" appe...|\n|  low|      0.0|\"big capacity\" co...|\n|  low|      0.0|\"big\" amazon brok...|\n|  low|      0.0|\"conflict of inte...|\n|  low|      0.0|\"convention girl\"...|\n|  low|      0.0|\"did you take tha...|\n|  low|      0.0|\"dolgyal\" is a in...|\n|  low|      0.0|\"double exposure\"...|\n|  low|      0.0|\"easy & quick set...|\n|  low|      0.0|\"energy\" was the ...|\n|  low|      0.0|\"fits most golf c...|\n|  low|      0.0|\"from the directo...|\n+-----+---------+--------------------+\nonly showing top 20 rows\n\n1624.16 seconds elasped"}], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "trainingData.cache()\ntestData.cache()\n\nprint(trainingData.count())\nprint(testData.count())", "outputs": [], "metadata": {"collapsed": true}}, {"source": "## 1. TFIDF", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# Some sample data to use\n# to save time ...\n\nsampleData = sqlContext.createDataFrame([\n  (0.0, \"Hi, I heard about Spark\"),\n  (0.0, \"I couldn't wish Java was any different\"),\n  (1.0, \"Logistic regression models are super boring\")], \n                        [\"sentiment\", \"sentences\"])\nsampleData.show()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# Example to get ngrams-range\nfrom itertools import chain\nfrom pyspark.sql.types import ArrayType, StringType\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.ml.feature import NGram\n\nclass nGramRanger:\n    \n    \"\"\"\n    \n    Wrapper around pyspark.ml.feature.Ngram which calls it in a loop and produces a \n    range of ngrams as features. \n    \n    ngramRange = (1,3) creates Ngram(1) and Ngram(2) and Ngram(3) in interim\n    and produces ngrams.\n    \n    \"\"\"\n    \n    def __init__(self, ngramRange, inputCol, outputCol = \"ngrams\"):\n        # ngramRange = (1,3)\n        self.ngramRange = ngramRange\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def transform(self, inDf):\n        _orig = inDf\n        def concat(type):\n            def concat_(*args):\n                return list(chain(*args))\n            return udf(concat_, ArrayType(type))\n        \n        # Create columns for n-grams\n        for ngr in range(self.ngramRange[0],self.ngramRange[-1]+1):\n            ngram = NGram(inputCol=self.inputCol , n=ngr, outputCol=\"%sgram\" % ngr)\n            inDf = ngram.transform(inDf)        \n        # Combine\n        concat_string_arrays = concat(StringType())\n        ###!!!!! FIx this at some point as 3 grams manually !!!!!\n        outDta = _orig.join(inDf.select(concat_string_arrays(col(\"1gram\"),\n                                                             col(\"2gram\"),\n                                                             col(\"3gram\")).alias(self.outputCol)))\n        # Return dataframe\n        return outDta\n\n\"\"\"\ntokenizer = Tokenizer(inputCol=\"sentences\", outputCol=\"words\")\ntokenisedData = tokenizer.transform(sampleData)\n\nstopremover = StopWordsRemover(inputCol=\"words\", outputCol=\"wordsFiltered\")\nstoppedData = stopremover.transform(tokenisedData)\n\nngrammer = nGramRanger(ngramRange = (1,3), inputCol = \"wordsFiltered\", outputCol = \"ngrams\")\noutput_test = ngrammer.transform(stoppedData)\n\nfor rw in output_test.take(5):\n    print(rw)\n\"\"\"", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# Pipeline for feature selection and classification\n# Using https://spark.apache.org/docs/1.5.2/ml-features.html\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, NGram\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n\n\nnumfeat = 40000\nngram_range = (1,3)\n\ntic()\n\n# 1. Feature-extraction\ntokenizer = Tokenizer(inputCol=\"sentences\", outputCol=\"words\")\nngrammer = nGramRanger(ngramRange = ngram_range, inputCol = \"words\", outputCol = \"ngrams\")\nhashingtf  = HashingTF(inputCol=\"ngrams\", outputCol=\"rawFeatures\", numFeatures=numfeat)\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n\n# Train\ntokenized_train = tokenizer.transform(trainingData)\nngrammed_train = ngrammer.transform(tokenized_train)\nhashed_train = hashingtf.transform(ngrammed_train)\nidfModel = idf.fit(hashed_train)\nidf_train = idfModel.transform(hashed_train)\n\n# Test\ntokenized_test = tokenizer.transform(testData)\nngrammed_test = ngrammer.transform(tokenized_test)\nhashed_test = hashingtf.transform(ngrammed_test)\nidf_test = idfModel.transform(hashed_test)\n\ntoc()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# 2A. Classifier (Logistic Regression)\ntic()\n\nclassi = LogisticRegression(labelCol=\"sentiment\", featuresCol=\"features\")\ntfidfModel = classi.fit(idf_train)\npred = tfidfModel.transform(idf_test)\n\ntoc()  \n\n# 3. Examine\nnumSuccesses = pred.where(\"\"\"(prediction = sentiment)\"\"\").count()\nnumInspections = numSuccesses + pred.where(\"\"\"(prediction != sentiment)\"\"\").count()\nacc = (float(numSuccesses) / float(numInspections)) * 100\nprint(\"%.2f\\% success rate\" % acc) # 49.74 success rate", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "# 2B. Classifier (RandomForest)\ntic()\n\nclassi = RandomForestClassifier(labelCol=\"sentiment\", featuresCol=\"features\")\ntfidfModel = classi.fit(idf_train)\npred = tfidfModel.transform(idf_test)\n\ntoc()  \n\n# 3. Examine\nnumSuccesses = pred.where(\"\"\"(prediction = sentiment)\"\"\").count()\nnumInspections = numSuccesses + pred.where(\"\"\"(prediction != sentiment)\"\"\").count()\nacc = (float(numSuccesses) / float(numInspections)) * 100\nprint(\"%.2f\\% success rate\" % acc) # 49.74 success rate", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "# 2C. Classifier (GBTClassifier)\ntic()\n\nclassi = GBTClassifier(labelCol=\"sentiment\", featuresCol=\"features\")\ntfidfModel = classi.fit(idf_train)\npred = tfidfModel.transform(idf_test)\n\ntoc()  \n\n# 3. Examine\nnumSuccesses = pred.where(\"\"\"(prediction = sentiment)\"\"\").count()\nnumInspections = numSuccesses + pred.where(\"\"\"(prediction != sentiment)\"\"\").count()\nacc = (float(numSuccesses) / float(numInspections)) * 100\nprint(\"%.2f\\% success rate\" % acc) # 49.74 success rate", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Running this locally got totally different results. \n\nBriefly:\n\n```\n# Cleaning\ndef clean_review(review):\n    temp = BeautifulSoup(review, \"lxml\").get_text()\n    punctuation = \"\"\".,?!:;(){}[]\"\"\"\n    for char in punctuation\n        temp = temp.replace(char, ' ' + char + ' ')\n    words = \" \".join(temp.lower().split()) + \"\\n\"\n    return words\n\n# Vectoriser\nvectorizer = TfidfVectorizer(max_features = 40000, ngram_range = (1, 3), sublinear_tf = True)\n\n# Classification using LR\nclassifier_tfidf = LogisticRegression()\n\n\n\n\n# Review\nclassifier_tfidf.fit(train_data_features, train_labels)\nclassifier_tfidf.score(test_data_features, test_labels) \n```\n\n* 50k gives 0.91479748910479386\n* 500k gives 0.92755933545886227\n* 1mill gives 0.93064867578787447\n\n*Cannot get anywhere near that in spark?!*", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# 3. Evaluation\npred.select(col('prediction'),col('sentiment')).show()", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "widgets": {"state": {"4874b2bd046049ac8e30cb3b3851496a": {"views": []}, "99561537b24e4555a6d16d03e69b8ecc": {"views": []}, "29beee2e535043dea562b54ea00a001b": {"views": []}, "28f8d70338ac403db9b5feab9bff1548": {"views": []}, "1a757cd393f443e3ab22c0d2fd1bdb6f": {"views": []}, "9772269d2e7f4923a2cddee96abc421f": {"views": []}, "b0f2a46046894d0ca581caf143c16e71": {"views": []}, "9f608dd6692b417999e8d7fe5823a898": {"views": []}, "8fbf815e87d743d4a703a10c32395d1b": {"views": []}, "aaf494efbba5455eb84a4511529884ca": {"views": []}, "084373f144f540a6b963a97805572e5e": {"views": []}, "1e94d2cc097042e7a20c2cf36a19fea9": {"views": []}, "d4a22d607882436cad789891e14c2ee1": {"views": []}, "ede1cff705fe4dc1900d1d6d326baadc": {"views": []}, "168ba3bf759f42d79cd8ff5abca0d9cd": {"views": []}, "713195116aeb436899d0cc56fb3eadb6": {"views": []}, "dc62ca4beba148ecb230c123ee2b4007": {"views": []}, "edac5daae76f4b8f9dbc552a92bbb6f3": {"views": []}, "e7ae12833e994be2979c99a5ed9afeed": {"views": []}, "acf422e7872d4376be18ff4f3968439e": {"views": []}, "465aefa57e3a4901bab6f84e7ccc6b05": {"views": []}, "734baac9a59b4d1799292fcd1e7e068b": {"views": []}, "abd8a91aef804d9389bb3fff0eacb1ab": {"views": []}, "3981bf0937ab4b60ad3353e8b7871f8f": {"views": []}, "265a7da6637a4529bd63e9b09e37a93f": {"views": []}, "ab698b0a60524dc39d96c7ae4819ed7c": {"views": []}, "6593945ce1ff42f395eceec187d49fed": {"views": []}, "f2430d2e55604941857d96be78807498": {"views": []}, "32fd815a749f4869b5b96c1e045490f6": {"views": []}, "c4b672c682924a0ab42c6fcca3d22213": {"views": []}, "954ad5319a0a49d193b3e02167ae4bc1": {"views": []}, "4a950018552847c48e60a2361b19a710": {"views": []}, "5cfa51bad7a1438b84bdefba3e223e87": {"views": []}, "e41182a9c2ea4ee9b3c879abb68029e4": {"views": [{"cell_index": 6}]}, "03b98882136d45aaa89a163e737d9d92": {"views": []}, "9f98e49dd64f4718975c1479338a4905": {"views": []}, "e8fea3aaa5db49d6ba28a3be2111db04": {"views": []}, "32d264b085b0416eaa09389a3e3eb83b": {"views": []}, "87130bc82335422681b57aaa6cac4194": {"views": []}, "c5ef2009547247f2982b673bb1fd8fc8": {"views": [{"cell_index": 7}]}, "e267993a890a48f88ead401038ab5f67": {"views": []}, "98931c3f7d944fae8e8e7a3671a443f9": {"views": []}, "8ef0fe7590fa4680a79d6304d40896e9": {"views": []}, "0e909cb41db74fbc9eafdf444044a58b": {"views": []}, "3697398dc81c486ca691f5329a1d3ad4": {"views": []}, "5dcd7a0f3e2c45f99853a6cf5579ea27": {"views": []}, "36d85e9e653048d0b61d9e883354b07c": {"views": []}, "52f8b2a9185f495598c69452218d68b8": {"views": []}, "d31421186ff943d7bd784973e454a0e4": {"views": []}, "81d7f604e4eb44f2bfbffd2547779c70": {"views": []}, "bf158f3595b64aacb6ff7775c42d2c62": {"views": []}, "71a3085f16374d2085ac1f49655c10a6": {"views": []}, "79d0b34e38414fe992b46f314c0fc991": {"views": []}, "a634723e26b04266ac16ad0893a551ee": {"views": []}, "bb17daeea24a4cca932321f831f5d1b8": {"views": [{"cell_index": 6}]}, "43323de0a98c4026928f8c0548662c4c": {"views": []}, "d1a08fb16f3d4dec913a0fa312e66bb4": {"views": [{"cell_index": 7}]}, "62b909828b0f4dcb80b4d44fcde29689": {"views": []}, "6f6bd9ad15e74b46aed910140109ee34": {"views": []}, "6b29bcd41b0144ae9187173d8c48ef83": {"views": []}, "9786623d44fe4d408f5dad87905cb3a5": {"views": []}, "582ccea8421f4536a38aeb88a367fdde": {"views": []}, "8c2be72303b74732bd006b82079e9e67": {"views": []}, "a75bba8f31194afeac890dac6cc554f1": {"views": []}, "a6d84e6b78b04cf3a3c38df5d59862de": {"views": []}, "7e44aad2dfba458f8593eda00bfbba07": {"views": []}, "0ce1b1849785456992ff4618e3eb5fe2": {"views": []}, "15fdf0e343dc4c3f9a3de39986f3df98": {"views": []}, "42758a30feab4f079e8b2f4b2d90270a": {"views": []}, "6e27ed13f7614870a157b005e3bac3e1": {"views": []}, "ba62a68c5e11438697b43344d88beea8": {"views": []}, "520c784d334f43339cbf688231780411": {"views": []}, "40f06ca4fbbf400289e874641f03f32b": {"views": []}, "040fc639daa54032971e1cb18c136983": {"views": []}, "5eaffeaf5a064ef0a746e5d58a6017e1": {"views": []}, "562f32562b7e4101ab3d3e8af66ec5f8": {"views": []}, "d012fe6420f54d1b899822869ddae9af": {"views": []}, "4c8c1ab4c1ca4dafa2cf4607081eb4f2": {"views": []}, "828493b031ca49f5b3289efbf107d350": {"views": []}, "c51304858c484ecb86b92ce8731fdca8": {"views": []}, "031abfda7b4d4a05ae45b20f56485eda": {"views": []}, "411f3ac201234d688e296940fab328a4": {"views": []}, "02455588b4704e5481336226feda15b9": {"views": []}, "b56fd92ab34647348f5a70de938ed0e7": {"views": []}, "4391cbf0b233479c8be3acbf4904d6b0": {"views": []}, "8e9995a4cc034d99aaac6608bfee9d09": {"views": []}, "45e096e4607e41139bc70d0f81f8f237": {"views": []}, "32e8a475b2164af1b1a88a7b7ef07f65": {"views": []}}, "version": "1.1.2"}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"name": "python"}}}}