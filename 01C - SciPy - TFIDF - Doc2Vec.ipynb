{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  Doc2Vec Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from random import shuffle\n",
    "import multiprocessing\n",
    "\n",
    "import gensim.models.doc2vec\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(cores)\n",
    "\n",
    "model_feat_size = 100\n",
    "\n",
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "    \n",
    "    def extract_sentences(self):\n",
    "        self.sentences = []\n",
    "        for sr, pr in self.sources.items():\n",
    "            with utils.smart_open(sr) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(),\n",
    "                                                          [pr + '_%s' % item_no]))\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        shuffle(self.sentences)\n",
    "        return self.sentences        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This will be a list of all sentences\n",
    "sentences = LabeledLineSentence(sources)\n",
    "sentences.extract_sentences()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mikov's params for IMDB](http://nbviewer.jupyter.org/github/fbkarsdorp/doc2vec/blob/master/quoc-response.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d100,n5,w5,mc2,t24)\n",
      "Doc2Vec(dbow,d100,n5,mc2,t24)\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,t24)\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Creating models using params from Mikolov above and here:\n",
    "# https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb\n",
    "# Number of features reduced to 100 from 400 to reduce training time\n",
    "\n",
    "single_models = [\n",
    "    # PV-DM with concatenation (window is on both side so actually *2)\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=model_feat_size, window=5, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW\n",
    "    Doc2Vec(dm=0, size=model_feat_size, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DM with averaging\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=model_feat_size, window=10, negative=5, hs=0, min_count=2, workers=cores)\n",
    "]\n",
    "\n",
    "single_models[0].build_vocab(sentences.sentences)\n",
    "print(single_models[0])\n",
    "\n",
    "# Use learnt vocab for other models\n",
    "for mod in single_models[1:]:\n",
    "    mod.reset_from(single_models[0])\n",
    "    print(mod)\n",
    "\n",
    "nms = ['dm_concat', 'dbow', 'dm_averaging']\n",
    "models = OrderedDict((str(name), model) for model, name in zip(single_models, nms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('dm_concat', <gensim.models.doc2vec.Doc2Vec object at 0x000001F9B8B09EF0>), ('dbow', <gensim.models.doc2vec.Doc2Vec object at 0x000001F9B8B09F28>), ('dm_averaging', <gensim.models.doc2vec.Doc2Vec object at 0x000001F9B8B09F98>), ('dbow_dmm', <gensim.test.test_doc2vec.ConcatenatedDoc2Vec object at 0x000001F9B8AF5F60>), ('dbow_dmc', <gensim.test.test_doc2vec.ConcatenatedDoc2Vec object at 0x000001F9B8AF5F28>)])\n"
     ]
    }
   ],
   "source": [
    "# Also use concatenated vectors from each model\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "models['dbow_dmm'] = ConcatenatedDoc2Vec([single_models[1], single_models[2]])\n",
    "models['dbow_dmc'] = ConcatenatedDoc2Vec([single_models[1], single_models[0]])\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: dm_concat\n",
      "Training epoch: 1\n",
      "Training epoch: 2\n",
      "Training epoch: 3\n",
      "Training epoch: 4\n",
      "Training epoch: 5\n",
      "Training epoch: 6\n",
      "Training epoch: 7\n",
      "Training epoch: 8\n",
      "Training epoch: 9\n",
      "Training epoch: 10\n",
      "Training epoch: 11\n",
      "Training epoch: 12\n",
      "Training epoch: 13\n",
      "Training epoch: 14\n",
      "Training epoch: 15\n",
      "Training epoch: 16\n",
      "Training epoch: 17\n",
      "Training epoch: 18\n",
      "Training epoch: 19\n",
      "Training epoch: 20\n",
      "Finished training model: dm_concat\n",
      "Training model: dbow\n",
      "Training epoch: 1\n",
      "Training epoch: 2\n",
      "Training epoch: 3\n",
      "Training epoch: 4\n",
      "Training epoch: 5\n",
      "Training epoch: 6\n",
      "Training epoch: 7\n",
      "Training epoch: 8\n",
      "Training epoch: 9\n",
      "Training epoch: 10\n",
      "Training epoch: 11\n",
      "Training epoch: 12\n",
      "Training epoch: 13\n",
      "Training epoch: 14\n",
      "Training epoch: 15\n",
      "Training epoch: 16\n",
      "Training epoch: 17\n",
      "Training epoch: 18\n",
      "Training epoch: 19\n",
      "Training epoch: 20\n",
      "Finished training model: dbow\n",
      "Training model: dm_averaging\n",
      "Training epoch: 1\n",
      "Training epoch: 2\n",
      "Training epoch: 3\n",
      "Training epoch: 4\n",
      "Training epoch: 5\n",
      "Training epoch: 6\n",
      "Training epoch: 7\n",
      "Training epoch: 8\n",
      "Training epoch: 9\n",
      "Training epoch: 10\n",
      "Training epoch: 11\n",
      "Training epoch: 12\n",
      "Training epoch: 13\n",
      "Training epoch: 14\n",
      "Training epoch: 15\n",
      "Training epoch: 16\n",
      "Training epoch: 17\n",
      "Training epoch: 18\n",
      "Training epoch: 19\n",
      "Training epoch: 20\n",
      "Finished training model: dm_averaging\n",
      "Training model: dbow_dmm\n",
      "Training epoch: 1\n",
      "Training epoch: 2\n",
      "Training epoch: 3\n",
      "Training epoch: 4\n",
      "Training epoch: 5\n",
      "Training epoch: 6\n",
      "Training epoch: 7\n",
      "Training epoch: 8\n",
      "Training epoch: 9\n",
      "Training epoch: 10\n",
      "Training epoch: 11\n",
      "Training epoch: 12\n",
      "Training epoch: 13\n",
      "Training epoch: 14\n",
      "Training epoch: 15\n",
      "Training epoch: 16\n",
      "Training epoch: 17\n",
      "Training epoch: 18\n",
      "Training epoch: 19\n",
      "Training epoch: 20\n",
      "Finished training model: dbow_dmm\n",
      "Training model: dbow_dmc\n",
      "Training epoch: 1\n",
      "Training epoch: 2\n",
      "Training epoch: 3\n",
      "Training epoch: 4\n",
      "Training epoch: 5\n",
      "Training epoch: 6\n",
      "Training epoch: 7\n",
      "Training epoch: 8\n",
      "Training epoch: 9\n",
      "Training epoch: 10\n",
      "Training epoch: 11\n",
      "Training epoch: 12\n",
      "Training epoch: 13\n",
      "Training epoch: 14\n",
      "Training epoch: 15\n",
      "Training epoch: 16\n",
      "Training epoch: 17\n",
      "Training epoch: 18\n",
      "Training epoch: 19\n",
      "Training epoch: 20\n",
      "Finished training model: dbow_dmc\n"
     ]
    }
   ],
   "source": [
    "# Train (five) model:\n",
    "for nme, model in models.items():\n",
    "       \n",
    "    alpha, min_alpha, epochs = (0.025, 0.001, 20)\n",
    "    alpha_delta = (alpha - min_alpha) / epochs\n",
    "\n",
    "    print(\"Training model: %s\" % nme)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(\"Training epoch: %d\" % (epoch+1))\n",
    "\n",
    "        model.alpha, model.min_alpha = alpha, alpha\n",
    "        model.train(sentences.sentences_perm())\n",
    "        alpha -= alpha_delta\n",
    "\n",
    "    print(\"Finished training model: %s\" % nme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the dictionary of models\n",
    "import pickle\n",
    "\n",
    "# Save\n",
    "pickle.dump(models, open(\"trained_models_400d_1mill.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Load\n",
    "####################################################################\n",
    "\n",
    "#models = pickle.load(open(\"trained_models_100d_1mill.pickle\",\"rb\"))\n",
    "models = pickle.load(open(\"trained_models_100d_1mill.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TE_B': 500208, 'TE_G': 500419, 'TR_G': 499581, 'TR_B': 499792}\n",
      "dm_concat Doc2Vec(dm/c,d100,n5,w5,mc2,t24)\n",
      "999373 for training\n",
      "1000627 for testing\n",
      "Model: dm_concat scored: 0.78047\n",
      "dbow Doc2Vec(dbow,d100,n5,mc2,t24)\n",
      "999373 for training\n",
      "1000627 for testing\n",
      "Model: dbow scored: 0.85409\n",
      "dm_averaging Doc2Vec(dm/m,d100,n5,w10,mc2,t24)\n",
      "999373 for training\n",
      "1000627 for testing\n",
      "Model: dm_averaging scored: 0.81205\n",
      "Array shape x 2\n",
      "dbow_dmm <gensim.test.test_doc2vec.ConcatenatedDoc2Vec object at 0x000001F7074922B0>\n",
      "999373 for training\n",
      "1000627 for testing\n",
      "Model: dbow_dmm scored: 0.85895\n",
      "Array shape x 2\n",
      "dbow_dmc <gensim.test.test_doc2vec.ConcatenatedDoc2Vec object at 0x000001F707492390>\n",
      "999373 for training\n",
      "1000627 for testing\n",
      "Model: dbow_dmc scored: 0.85641\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Check sizes\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "# Dictionary of file-lengths\n",
    "file_lengths = {}\n",
    "for k,v in sources.items():\n",
    "    file_lengths[v] = file_len(k)\n",
    "print(file_lengths)\n",
    "\n",
    "for nme, model in models.items():\n",
    "    \n",
    "    if \"Concatenated\" in str(model):\n",
    "        print(\"Array shape x 2\")\n",
    "        array_shape = 2*model_feat_size\n",
    "    else:\n",
    "        array_shape = model_feat_size\n",
    "    \n",
    "    print(nme, model)\n",
    "    \n",
    "    # Train vectors\n",
    "    no_training = file_lengths['TR_G'] + file_lengths['TR_B']\n",
    "    print(\"%d for training\" % no_training)\n",
    "\n",
    "    train_arrays = numpy.zeros((no_training, array_shape))\n",
    "    train_labels = numpy.concatenate((numpy.ones(file_lengths['TR_G']),\n",
    "                                      numpy.zeros(file_lengths['TR_B'])))\n",
    "\n",
    "    for i in range(file_lengths['TR_G']):\n",
    "        train_arrays[i] = model.docvecs['TR_G_' + str(i)]\n",
    "\n",
    "    for i in range(file_lengths['TR_B']):\n",
    "        train_arrays[file_lengths['TR_G'] + i] = model.docvecs['TR_B_' + str(i)]\n",
    "\n",
    "    assert len(train_arrays) == len(train_labels)\n",
    "\n",
    "    classifier = LogisticRegression()  \n",
    "    classifier.fit(train_arrays, train_labels)\n",
    "\n",
    "    del train_arrays\n",
    "    del train_labels\n",
    "\n",
    "    # Test vectors\n",
    "    no_testing = file_lengths['TE_G'] + file_lengths['TE_B']\n",
    "    print(\"%d for testing\" % no_testing)\n",
    "\n",
    "    test_arrays = numpy.zeros((no_testing, array_shape))\n",
    "    test_labels = numpy.concatenate((numpy.ones(file_lengths['TE_G']),\n",
    "                                      numpy.zeros(file_lengths['TE_B'])))\n",
    "\n",
    "    for i in range(file_lengths['TE_G']):\n",
    "        test_arrays[i] = model.docvecs['TE_G_' + str(i)]\n",
    "\n",
    "    for i in range(file_lengths['TE_B']):\n",
    "        test_arrays[file_lengths['TE_G'] + i] = model.docvecs['TE_B_' + str(i)]\n",
    "\n",
    "    assert len(test_arrays) == len(test_labels)\n",
    "    acc = classifier.score(test_arrays, test_labels)\n",
    "\n",
    "    print(\"Model: %s scored: %.5f\" % (nme, acc))\n",
    "    # 0.0.85895 highest from ConcatenatedDoc2Vec(dbow, dmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.56832957,  1.2058115 ,  0.14491647, -0.42551604, -0.38818172,\n",
       "       -0.8952595 , -0.4061074 ,  1.6264652 ,  0.57415462, -1.82958436,\n",
       "        1.04183209,  0.66710657,  1.49038315, -1.95077193,  0.9098739 ,\n",
       "        0.85745955,  1.43841267,  1.03374803,  0.68891966, -1.03387189,\n",
       "        1.8800143 ,  1.0016433 ,  0.15377448, -0.13892122,  0.62905884,\n",
       "        1.17400193,  0.30953103, -1.33326066, -1.6362499 , -1.03263128,\n",
       "       -1.9761641 , -0.5444386 , -0.0458766 ,  1.72448826,  0.46611884,\n",
       "       -1.50342023,  1.06823838,  0.83525628,  0.02131413,  0.11638412,\n",
       "        1.10794115, -1.03421974, -0.37249202,  0.74126559, -2.26668239,\n",
       "        1.09970188,  2.04381251, -1.00660169, -0.10463743,  1.28817487,\n",
       "        0.65644276,  1.72466075, -1.62890887,  0.55496752, -2.7380898 ,\n",
       "        0.65241426,  0.21561557,  0.00379093, -0.5218727 , -0.49999937,\n",
       "       -3.32112288,  0.03845607, -0.41876355,  0.70093024,  2.54490423,\n",
       "       -0.04950583, -0.11358964,  2.10094333,  1.87797546,  1.53694439,\n",
       "       -0.38410744,  0.87793159, -0.53272527,  1.95610189,  0.02170982,\n",
       "       -2.44544482, -0.96742219,  2.46106935, -0.37373033,  0.45923868,\n",
       "       -1.19433773, -2.18600583,  1.02160788,  0.52610505, -1.22757566,\n",
       "        0.92709887,  0.09480499,  0.68203688, -0.3146469 ,  2.01290202,\n",
       "        0.30745193,  0.63879448,  0.96413773, -1.56254268, -0.27959421,\n",
       "        0.04107908,  0.14027235,  0.78004473, -0.4113183 , -1.40744257], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does a sample vector look like?\n",
    "model.docvecs['TE_G_10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Play around with the features of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models['dm_averaging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247718\n"
     ]
    }
   ],
   "source": [
    "print(len(model.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similar words:\n",
    "# cosine similarity between a simple mean of the projection weight vectors \n",
    "# of the given words and the vectors for each word in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 0.9756659269332886),\n",
       " ('game', 0.9631760120391846),\n",
       " ('book', 0.9562268257141113),\n",
       " ('novel', 0.9456548690795898),\n",
       " ('series', 0.9344912767410278),\n",
       " ('story', 0.9277447462081909),\n",
       " ('toy', 0.9255129098892212),\n",
       " ('documentary', 0.9239569306373596),\n",
       " ('album', 0.9229424595832825),\n",
       " ('product', 0.9229174256324768)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('novel', 0.9667423963546753),\n",
       " ('film', 0.9627326726913452),\n",
       " ('movie', 0.9562268257141113),\n",
       " ('product', 0.9447879791259766),\n",
       " ('game', 0.9428784251213074),\n",
       " ('item', 0.9405743479728699),\n",
       " ('series', 0.9339053630828857),\n",
       " ('cd', 0.9305703639984131),\n",
       " ('cookbook', 0.924953818321228),\n",
       " ('unit', 0.9230896830558777)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('brust', 0.7509414553642273),\n",
       " ('seagal', 0.6961789131164551),\n",
       " ('godard', 0.6865265369415283),\n",
       " ('altman', 0.6823572516441345),\n",
       " ('costner', 0.6704180240631104),\n",
       " ('alten', 0.6646450757980347),\n",
       " ('hitchcock', 0.6628223657608032),\n",
       " ('spielburg', 0.6588513851165771),\n",
       " ('bowie', 0.6585037708282471),\n",
       " ('paolini', 0.6476680040359497)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('spielberg')\n",
    "# Godard and Spielberg? \n",
    "# Google search: \"Godard accuses filmmaker Steven Spielberg of never paying Emilie Schindler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dissapointed', 0.9665608406066895),\n",
       " ('dissappointed', 0.9549894332885742),\n",
       " ('disapointed', 0.9537227153778076),\n",
       " ('upset', 0.8508213758468628),\n",
       " ('impressed', 0.8426313400268555),\n",
       " ('displeased', 0.8382212519645691),\n",
       " ('disspointed', 0.8305480480194092),\n",
       " ('diappointed', 0.8276960849761963),\n",
       " ('disapponted', 0.8072155714035034),\n",
       " ('disppointed', 0.7938259243965149)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('disappointed')\n",
    "# Are spelling mistakes really an issue if they are captured by the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** However, look at some of the most similar results to these: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.8415285348892212),\n",
       " ('nice', 0.8255696296691895),\n",
       " ('decent', 0.8067948818206787),\n",
       " ('bad', 0.7878735065460205),\n",
       " ('satisfactory', 0.7774009704589844),\n",
       " ('reasonable', 0.7503374814987183),\n",
       " ('terrific', 0.7394672632217407),\n",
       " ('stellar', 0.7384458780288696),\n",
       " ('weak', 0.7360069155693054),\n",
       " ('lousy', 0.7356691956520081)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('good')\n",
    "# ('bad', 0.7878735065460205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.9617341160774231),\n",
       " ('enjoyed', 0.9531521797180176),\n",
       " ('hated', 0.940513014793396),\n",
       " ('love', 0.9257104396820068),\n",
       " ('hate', 0.8870297074317932),\n",
       " ('knew', 0.8754450082778931),\n",
       " ('disliked', 0.8680945038795471),\n",
       " ('saw', 0.8665635585784912),\n",
       " ('returned', 0.8661980032920837),\n",
       " ('enjoy', 0.8642623424530029)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('liked')\n",
    "# ('hated', 0.940513014793396)\n",
    "# Notice that the past-tense is captured (loved more likely than love)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('awesome', 0.958543062210083),\n",
       " ('incredible', 0.9484298229217529),\n",
       " ('outstanding', 0.9301931262016296),\n",
       " ('awsome', 0.8869935870170593),\n",
       " ('excellent', 0.883213460445404),\n",
       " ('exceptional', 0.8818068504333496),\n",
       " ('awful', 0.8477048873901367),\n",
       " ('astounding', 0.8337091207504272),\n",
       " ('extraordinary', 0.8214305639266968),\n",
       " ('astonishing', 0.8043204545974731)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('amazing')\n",
    "# ('awful', 0.8477048873901367)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We have no distinction between synonyms and antonyms. For me this seems crucial ... **\n",
    "\n",
    "** Basically, similarity('bad', 'good') > similarity('good', 'reasonable') **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.6947972774505615),\n",
       " ('queen', 0.6658217906951904),\n",
       " ('bishop', 0.6533105969429016),\n",
       " ('baxter', 0.6368122100830078),\n",
       " ('weber', 0.6214838027954102),\n",
       " ('goliath', 0.6017906665802002),\n",
       " ('pope', 0.5975253582000732),\n",
       " ('elton', 0.5942682027816772),\n",
       " ('legend', 0.5937572121620178),\n",
       " ('stone', 0.5932419300079346)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ('queen', 0.6658217906951904)\n",
    "model.most_similar(positive=['king','woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similar documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is and does exactly what the description said it would be and would do . couldn ' t be happier with it .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def line_from_file(fname, line_no):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            if i == line_no:\n",
    "                return l\n",
    "            \n",
    "print(line_from_file('train_good_reviews.txt',0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TR_G_360872', 0.8071361780166626),\n",
       " ('TR_B_234248', 0.802955687046051),\n",
       " ('TR_G_385106', 0.7977914214134216),\n",
       " ('TR_B_128954', 0.7973953485488892),\n",
       " ('TR_G_322557', 0.7963820695877075),\n",
       " ('TE_G_122163', 0.7958847880363464),\n",
       " ('TE_G_304226', 0.794230580329895),\n",
       " ('TE_B_395691', 0.7940493822097778),\n",
       " ('TE_G_203933', 0.7899248600006104),\n",
       " ('TE_G_1155', 0.7880555391311646)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar('TR_G_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very compact and easy to use . does what they said it would do . i would recommend it to a friend .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(line_from_file('train_good_reviews.txt', 360872))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`it is and does exactly what the description said it would be and would do . couldn ' t be happier with it .`\n",
    "\n",
    "v.s.\n",
    "\n",
    "`very compact and easy to use . does what they said it would do . i would recommend it to a friend .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Infer documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TE_B_435805', 0.8324828147888184),\n",
       " ('TE_G_109719', 0.8270643353462219),\n",
       " ('TR_G_95891', 0.8243824243545532),\n",
       " ('TR_G_276590', 0.822350025177002),\n",
       " ('TE_B_200194', 0.8196755647659302)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_example = model.infer_vector(['this','broke','straight','out','of','the','box'])\n",
    "model.docvecs.most_similar([inferred_example], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this did not work .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ('TR_G_101591', 0.8730407953262329)\n",
    "print(line_from_file('test_bad_reviews.txt', 435805))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`['this','broke','straight','out','of','the','box']`\n",
    "\n",
    "v.s.\n",
    "\n",
    "`this did not work .`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
